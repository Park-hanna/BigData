{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3353efc4-c1fc-47b8-a3e0-a455d670dc06",
   "metadata": {},
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a47a8b19-b4b9-4447-925b-49366791f730",
   "metadata": {},
   "source": [
    "## Open Domain conversation task for Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6780a12-6ef8-4937-853c-baec2d47d40f",
   "metadata": {},
   "source": [
    "### dataset : https://github.com/songys/Chatbot_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2df15b5-8e17-488f-9fbc-875b6fcb5813",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q</th>\n",
       "      <th>A</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12시 땡!</td>\n",
       "      <td>하루가 또 가네요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1지망 학교 떨어졌어</td>\n",
       "      <td>위로해 드립니다.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3박4일 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3박4일 정도 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PPL 심하네</td>\n",
       "      <td>눈살이 찌푸려지죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Q            A  label\n",
       "0           12시 땡!   하루가 또 가네요.      0\n",
       "1      1지망 학교 떨어졌어    위로해 드립니다.      0\n",
       "2     3박4일 놀러가고 싶다  여행은 언제나 좋죠.      0\n",
       "3  3박4일 정도 놀러가고 싶다  여행은 언제나 좋죠.      0\n",
       "4          PPL 심하네   눈살이 찌푸려지죠.      0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sentencepiece as spm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "train_data = pd.read_csv('./chatbot_data/dataset/ChatbotData.csv')\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d5a055b9-f3d8-4708-aa62-977cb877e865",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a66369-372a-45d5-b552-274aadc7a914",
   "metadata": {},
   "source": [
    "## a Voacb create with sentence piece"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82217c93-9692-4f3f-b3f7-ae25c1ecb698",
   "metadata": {},
   "source": [
    "### Sentence Piece : A simple and language indepemdent sub tokenizer and detokenizer for Neural Text Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5fe209b-96d9-4fa2-b50f-cfdcb3e47c2d",
   "metadata": {},
   "source": [
    "### * Taku Kudo, John Richardson, Google"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238a319e-e887-4cd1-9090-f2313c7f1ca3",
   "metadata": {},
   "source": [
    "RNN은 기본적으로 vocab의 크기가 계산량에 영향을 주고 있슴. 따라서 적당한 크기의 vocab을 사용하고 이때 문제가 많이 발생한다. 우리는 vocab을 만들때 미등록 단어가 발생하고 실제로 해당 단어가 들어왔을 시 UNK token으로 대체하게 된다. 이 과정에서 정보 손실이 발생하며 성능 문제가 일어날 수 있다. 이런 점을 보완하고자 sentencepiece를 tokenizer로 사용하고자 한다. sentencepiece의 기본 아이디어는 word의 subword로 모든 단어를 표현하고자 하는 것이다. 이때 사용하는게 단어들의 빈도수를 사용해 subword로 나눌지 말지를 판단한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d084393-323e-4455-b823-3e2a695e86db",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = \"./chatbot_data/dataset/chit-chat_corpus.txt\"\n",
    "prefix = 'chatbot'\n",
    "vocab_size = 16000\n",
    "spm.SentencePieceTrainer.train(\n",
    "    f\"--input={corpus} --model_prefix={prefix} --vocab_size={vocab_size + 7}\"+\n",
    "    \" --model_type=bpe\" +\n",
    "    \" --max_sentence_length=999999\" + # max sentence length\n",
    "    \" --pad_id=0 --pad_piece=[PAD]\" + # pad(0)\n",
    "    \" --unk_id=1 --unk_piece=[UNK]\" + # unknown(1)\n",
    "    \" --bos_id=2 --bos_piece=[BOS]\" + # begin of sequence(2)\n",
    "    \" --eos_id=3 --eos_piece=[EOS]\" + # end of sequence(3)\n",
    "    \" --user_defined_symbols=[SEP],[CLS],[MASK]\") # user define token"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d677d199-04f5-4a12-a3f9-7a4565c47041",
   "metadata": {},
   "source": [
    "## Load & Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e3094d42-6c90-45c6-a8a7-a84ab7c8701b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3박4일 정도 놀러가고 싶다\n",
      "['▁3', '박', '4', '일', '▁정도', '▁놀러가고', '▁싶다']\n",
      "[473, 15432, 15399, 14972, 982, 3503, 201]\n"
     ]
    }
   ],
   "source": [
    "vocab_file = \"chatbot.model\"\n",
    "vocab = spm.SentencePieceProcessor()\n",
    "vocab.load(vocab_file)\n",
    "line = \"3박4일 정도 놀러가고 싶다\"\n",
    "pieces = vocab.encode_as_pieces(line)\n",
    "ids = vocab.encode_as_ids(line)\n",
    "\n",
    "\n",
    "print(line)\n",
    "print(pieces)\n",
    "print(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2f13298f-f4e0-4237-830a-04ed12091b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import torch\n",
    "import random\n",
    "import torch.utils.data as data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from tqdm import tqdm\n",
    "from tqdm import trange\n",
    "\n",
    "import torch.nn.functional as F\n",
    "# import torch.utils.transboard import SummaryWriter\n",
    "\n",
    "from src.model import save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ecc66daf-488c-47f0-9a46-471e512cc598",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Processing:\n",
    "    \n",
    "    def __init__(self, max_len = 20):\n",
    "        self.max_len = max_len\n",
    "        self.PAD = 0\n",
    "        \n",
    "    def pad_idx_sequencing(self, q_vec):\n",
    "        q_len = len(q_vec)\n",
    "        diff_len = q_len - self.max_len\n",
    "        \n",
    "        if(diff_len > 0):\n",
    "            q_vec = q_vec[:self.max_len]\n",
    "            q_len = self.max_len\n",
    "\n",
    "        else:\n",
    "            pad_vac = [0] * abs(diff_len)\n",
    "            q_vec += pad_vac\n",
    "            \n",
    "        return q_vec\n",
    "    \n",
    "    def make_batch(self):\n",
    "        pass\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f91c89ea-a100-4632-bc07-807bda4381e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChitChatDataset(data.Dataset):\n",
    "    def __init__(self, x_tensor, y_tensor, labels):\n",
    "        super(ChitChatDataset, self).__init__()\n",
    "        \n",
    "        self.x = x_tensor\n",
    "        self.y = y_tensor\n",
    "        self.labels = labels\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.x[index], self.y[index], self.labels[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3d039b89-8e85-4d86-b463-060dbbd84441",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MakeDataset:\n",
    "    def __init__(self):\n",
    "        \n",
    "        self.chitchat_data_dir = './chatbot_data/dataset/ChatbotData.csv'\n",
    "        \n",
    "        self.prep = Processing()\n",
    "        vocab_file = 'chatbot.model'\n",
    "        self.transformers_tokenizer = spm.SentencePieceProcessor()\n",
    "        self.transformers_tokenizer.load(vocab_file)\n",
    "        \n",
    "    def encode_dataset(self, dataset):\n",
    "        token_dataset = []\n",
    "        for data in dataset:\n",
    "            token_dataset.append( [2] + self.transformers_tokenizer.encode_as_ids(data) + [3])\n",
    "        return token_dataset\n",
    "    \n",
    "    def make_chitchat_dataset(self, train_ratio = 0.8):\n",
    "        chitchat_dataset = pd.read_csv(self.chitchat_data_dir)\n",
    "        Qs = chitchat_dataset['Q'].tolist()\n",
    "        As = chitchat_dataset['A'].tolist()\n",
    "        label = chitchat_dataset['label'].tolist()\n",
    "        \n",
    "        Qs = self.encode_dataset(Qs)\n",
    "        As = self.encode_dataset(As)\n",
    "        \n",
    "        self.prep.max_len = 40\n",
    "        \n",
    "        x, y = [], []\n",
    "        for q, a in zip(Qs, As):\n",
    "            x.append(self.prep.pad_idx_sequencing(q))\n",
    "            y.append(self.prep.pad_idx_sequencing(a))\n",
    "            \n",
    "        x = torch.tensor(x)\n",
    "        y = torch.tensor(y)\n",
    "        x_len = x.size()[0]\n",
    "        train_size = int(x_len * train_ratio)\n",
    "        \n",
    "        if(train_ratio == 1.0):\n",
    "            train_x = x[:train_size]\n",
    "            train_y = y[:train_size]\n",
    "            train_label = label[:train_size]\n",
    "            train_dataset = ChitChatDataset(train_x, train_y, train_label)\n",
    "            return train_dataset, None\n",
    "        \n",
    "        else:\n",
    "            train_x = x[:train_size]\n",
    "            train_y = y[:train_size]\n",
    "            train_label = label[:train_size]\n",
    "            \n",
    "            test_x = x[train_size:]\n",
    "            test_y = y[train_size:]\n",
    "            test_label = label[train_size:]\n",
    "            \n",
    "            train_dataset = ChitChatDataset(train_x, train_y, train_label)\n",
    "            test_dataset = ChitChatDataset(test_x, test_y, test_label)\n",
    "            \n",
    "            return train_dataset, test_dataset\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c66f0330-21eb-40d0-b0a9-0736e9b16d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MakeDataset()\n",
    "\n",
    "train_dataset, test_dataset = dataset.make_chitchat_dataset(1.0)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size = 128, shuffle = True)\n",
    "#test_dataloader = DataLoader(test_dataset, batch_size = 128, shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41328ef1-7113-4cde-808d-ce2d8283a31a",
   "metadata": {},
   "source": [
    "# Attention Is All You Need\n",
    "## * Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, Illia Polosukhin\n",
    "### tensorflow transformer chatbot code : https://blog.tensorflow.org/2019/05/transformer-chatbot-tutorial-with-tensorflow-2.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "77faa47c-33ca-47ff-b91d-8bbd14442911",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Transformer\n",
    "from torch import nn\n",
    "import torch\n",
    "import math\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6ba3adaf-57d1-4d07-b68a-acdee4281585",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tformer(nn.Module):\n",
    "    def __init__(self, num_tokens, dim_model, num_heads, dff, num_layers, dropout_p=0.5):\n",
    "        super(Tformer, self).__init__()\n",
    "        self.transformer = Transformer(dim_model, num_heads, dim_feedforward=dff, num_encoder_layers=num_layers, num_decoder_layers=num_layers,dropout=dropout_p)\n",
    "        self.pos_encoder = PositionalEncoding(dim_model, dropout_p)\n",
    "        self.encoder = nn.Embedding(num_tokens, dim_model)\n",
    "\n",
    "        self.pos_encoder_d = PositionalEncoding(dim_model, dropout_p)\n",
    "        self.encoder_d = nn.Embedding(num_tokens, dim_model)\n",
    "\n",
    "        self.dim_model = dim_model\n",
    "        self.num_tokens = num_tokens\n",
    "\n",
    "        self.linear = nn.Linear(dim_model, num_tokens)\n",
    "\n",
    "    def generate_square_subsequent_mask(self, sz):\n",
    "        mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n",
    "        mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "        return mask\n",
    "\n",
    "    def forward(self, src, tgt, srcmask, tgtmask, srcpadmask, tgtpadmask):\n",
    "        src = self.encoder(src) * math.sqrt(self.dim_model)\n",
    "        src = self.pos_encoder(src)\n",
    "\n",
    "        tgt = self.encoder_d(tgt) * math.sqrt(self.dim_model)\n",
    "        tgt = self.pos_encoder_d(tgt)\n",
    "\n",
    "        output = self.transformer(src.transpose(0,1), tgt.transpose(0,1), srcmask, tgtmask, src_key_padding_mask=srcpadmask, tgt_key_padding_mask=tgtpadmask)\n",
    "        output = self.linear(output)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "77b9fb43-0184-4263-b246-c45f596a5e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, dropout=0.1, max_len = 5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p = dropout)\n",
    "        \n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer('pe', pe)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:x.size(0), :]\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a8d740bb-067a-459d-956d-f89075dea1f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_attention_mask(x):\n",
    "    mask = torch.eq(x, 0)\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6e520d0e-5f16-4a5e-88fe-11afff7e4ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Tformer(\n",
    "    num_tokens = vocab_size + 7, dim_model = 256, num_heads = 8, dff = 512, num_layers = 2, dropout_p = 0.1\n",
    ").cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2910c1cf-51e6-4ecb-87a5-4785d490fb4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-4\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = lr)\n",
    "MAX_LENGTH = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "279d8367-cee9-4d05-85bd-ace4648dd242",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.252: 100%|███████████████████████████████████████████████████████████████████████████| 93/93 [00:07<00:00, 12.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch :  1 | loss :  0.2763528106033161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.280: 100%|███████████████████████████████████████████████████████████████████████████| 93/93 [00:07<00:00, 12.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch :  2 | loss :  0.2695575837166079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.279: 100%|███████████████████████████████████████████████████████████████████████████| 93/93 [00:07<00:00, 12.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch :  3 | loss :  0.2634617179952642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.285: 100%|███████████████████████████████████████████████████████████████████████████| 93/93 [00:07<00:00, 12.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch :  4 | loss :  0.2570837082401399\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.251: 100%|███████████████████████████████████████████████████████████████████████████| 93/93 [00:07<00:00, 12.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch :  5 | loss :  0.25099984035697037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.196: 100%|███████████████████████████████████████████████████████████████████████████| 93/93 [00:07<00:00, 12.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch :  6 | loss :  0.24424312960716985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.250: 100%|███████████████████████████████████████████████████████████████████████████| 93/93 [00:07<00:00, 12.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch :  7 | loss :  0.23843057693973665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.226: 100%|███████████████████████████████████████████████████████████████████████████| 93/93 [00:07<00:00, 12.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch :  8 | loss :  0.23250397302771128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.268: 100%|███████████████████████████████████████████████████████████████████████████| 93/93 [00:07<00:00, 12.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch :  9 | loss :  0.22735692096012894\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.238: 100%|███████████████████████████████████████████████████████████████████████████| 93/93 [00:07<00:00, 12.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch :  10 | loss :  0.22086248090190272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.200: 100%|███████████████████████████████████████████████████████████████████████████| 93/93 [00:07<00:00, 12.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch :  11 | loss :  0.21477358828308762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.236: 100%|███████████████████████████████████████████████████████████████████████████| 93/93 [00:07<00:00, 12.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch :  12 | loss :  0.20952038098407047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.219: 100%|███████████████████████████████████████████████████████████████████████████| 93/93 [00:07<00:00, 12.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch :  13 | loss :  0.20389450237315188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.195: 100%|███████████████████████████████████████████████████████████████████████████| 93/93 [00:07<00:00, 12.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch :  14 | loss :  0.19887017691007225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.216: 100%|███████████████████████████████████████████████████████████████████████████| 93/93 [00:07<00:00, 12.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch :  15 | loss :  0.1931244634812878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.200: 100%|███████████████████████████████████████████████████████████████████████████| 93/93 [00:07<00:00, 11.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch :  16 | loss :  0.18823123234574513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.162: 100%|███████████████████████████████████████████████████████████████████████████| 93/93 [00:07<00:00, 12.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch :  17 | loss :  0.18272319916755922\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.177: 100%|███████████████████████████████████████████████████████████████████████████| 93/93 [00:07<00:00, 12.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch :  18 | loss :  0.17820811528031544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.175: 100%|███████████████████████████████████████████████████████████████████████████| 93/93 [00:07<00:00, 12.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch :  19 | loss :  0.17324863967075144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.212: 100%|███████████████████████████████████████████████████████████████████████████| 93/93 [00:07<00:00, 11.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch :  20 | loss :  0.16830010567941972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.191: 100%|███████████████████████████████████████████████████████████████████████████| 93/93 [00:07<00:00, 12.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch :  21 | loss :  0.1636394275132046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.155: 100%|███████████████████████████████████████████████████████████████████████████| 93/93 [00:07<00:00, 11.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch :  22 | loss :  0.15899810996106875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.132: 100%|███████████████████████████████████████████████████████████████████████████| 93/93 [00:07<00:00, 12.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch :  23 | loss :  0.1543963852749076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.153: 100%|███████████████████████████████████████████████████████████████████████████| 93/93 [00:07<00:00, 12.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch :  24 | loss :  0.15005028632379347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.140: 100%|███████████████████████████████████████████████████████████████████████████| 93/93 [00:07<00:00, 11.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch :  25 | loss :  0.1466256828718288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.152: 100%|███████████████████████████████████████████████████████████████████████████| 93/93 [00:07<00:00, 12.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch :  26 | loss :  0.14135238688479188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.122: 100%|███████████████████████████████████████████████████████████████████████████| 93/93 [00:07<00:00, 12.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch :  27 | loss :  0.138052858332152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.123: 100%|███████████████████████████████████████████████████████████████████████████| 93/93 [00:07<00:00, 11.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch :  28 | loss :  0.13322323624805738\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.121: 100%|███████████████████████████████████████████████████████████████████████████| 93/93 [00:07<00:00, 11.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch :  29 | loss :  0.12960755953224756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.150: 100%|███████████████████████████████████████████████████████████████████████████| 93/93 [00:07<00:00, 12.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch :  30 | loss :  0.12598404833065566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.126: 100%|███████████████████████████████████████████████████████████████████████████| 93/93 [00:07<00:00, 12.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch :  31 | loss :  0.12270651581466839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.119: 100%|███████████████████████████████████████████████████████████████████████████| 93/93 [00:07<00:00, 12.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch :  32 | loss :  0.11848138993786227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.118: 100%|███████████████████████████████████████████████████████████████████████████| 93/93 [00:07<00:00, 12.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch :  33 | loss :  0.11558063055879327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.123: 100%|███████████████████████████████████████████████████████████████████████████| 93/93 [00:07<00:00, 12.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch :  34 | loss :  0.11177829004103138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.106: 100%|███████████████████████████████████████████████████████████████████████████| 93/93 [00:07<00:00, 11.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch :  35 | loss :  0.10842477121660786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.124: 100%|███████████████████████████████████████████████████████████████████████████| 93/93 [00:07<00:00, 12.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch :  36 | loss :  0.10476181071291688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.112: 100%|███████████████████████████████████████████████████████████████████████████| 93/93 [00:07<00:00, 12.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch :  37 | loss :  0.10215080425303469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.107: 100%|███████████████████████████████████████████████████████████████████████████| 93/93 [00:07<00:00, 12.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch :  38 | loss :  0.09886711899952222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.104: 100%|███████████████████████████████████████████████████████████████████████████| 93/93 [00:07<00:00, 12.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch :  39 | loss :  0.09651817813996345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.084: 100%|███████████████████████████████████████████████████████████████████████████| 93/93 [00:09<00:00,  9.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch :  40 | loss :  0.09306544642294606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.090: 100%|███████████████████████████████████████████████████████████████████████████| 93/93 [00:12<00:00,  7.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch :  41 | loss :  0.09015446324502269\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.080: 100%|███████████████████████████████████████████████████████████████████████████| 93/93 [00:12<00:00,  7.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch :  42 | loss :  0.08726144606067289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.080: 100%|███████████████████████████████████████████████████████████████████████████| 93/93 [00:12<00:00,  7.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch :  43 | loss :  0.08489986132549983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.072: 100%|███████████████████████████████████████████████████████████████████████████| 93/93 [00:12<00:00,  7.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch :  44 | loss :  0.081668822996078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.082: 100%|███████████████████████████████████████████████████████████████████████████| 93/93 [00:12<00:00,  7.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch :  45 | loss :  0.07967700240432575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.079: 100%|███████████████████████████████████████████████████████████████████████████| 93/93 [00:12<00:00,  7.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch :  46 | loss :  0.07715594383978075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.084: 100%|███████████████████████████████████████████████████████████████████████████| 93/93 [00:12<00:00,  7.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch :  47 | loss :  0.07535171508789062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.076: 100%|███████████████████████████████████████████████████████████████████████████| 93/93 [00:08<00:00, 10.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch :  48 | loss :  0.07273582745623845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.068: 100%|███████████████████████████████████████████████████████████████████████████| 93/93 [00:07<00:00, 12.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch :  49 | loss :  0.07026692872406334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.063: 100%|███████████████████████████████████████████████████████████████████████████| 93/93 [00:07<00:00, 12.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch :  50 | loss :  0.06854471083610289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.071: 100%|███████████████████████████████████████████████████████████████████████████| 93/93 [00:07<00:00, 11.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch :  51 | loss :  0.0659976928464828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.057: 100%|███████████████████████████████████████████████████████████████████████████| 93/93 [00:07<00:00, 12.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch :  52 | loss :  0.06445241230790333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.050: 100%|███████████████████████████████████████████████████████████████████████████| 93/93 [00:07<00:00, 12.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch :  53 | loss :  0.062048491611275625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.058: 100%|███████████████████████████████████████████████████████████████████████████| 93/93 [00:07<00:00, 12.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch :  54 | loss :  0.06047274989466513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.057: 100%|███████████████████████████████████████████████████████████████████████████| 93/93 [00:07<00:00, 12.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch :  55 | loss :  0.0584888663343204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.058: 100%|███████████████████████████████████████████████████████████████████████████| 93/93 [00:07<00:00, 12.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch :  56 | loss :  0.05695457355950468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.057: 100%|███████████████████████████████████████████████████████████████████████████| 93/93 [00:07<00:00, 12.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch :  57 | loss :  0.05533288627542475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.057: 100%|███████████████████████████████████████████████████████████████████████████| 93/93 [00:07<00:00, 12.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch :  58 | loss :  0.053682440070695774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.060: 100%|███████████████████████████████████████████████████████████████████████████| 93/93 [00:07<00:00, 12.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch :  59 | loss :  0.05183704437748078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.069: 100%|███████████████████████████████████████████████████████████████████████████| 93/93 [00:07<00:00, 12.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch :  60 | loss :  0.05067741742698095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.047: 100%|███████████████████████████████████████████████████████████████████████████| 93/93 [00:07<00:00, 12.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch :  61 | loss :  0.0491843992663968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.048: 100%|███████████████████████████████████████████████████████████████████████████| 93/93 [00:07<00:00, 12.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch :  62 | loss :  0.047938700645200664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.056: 100%|███████████████████████████████████████████████████████████████████████████| 93/93 [00:07<00:00, 12.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch :  63 | loss :  0.04586177231163107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.053: 100%|███████████████████████████████████████████████████████████████████████████| 93/93 [00:07<00:00, 12.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch :  64 | loss :  0.04480537804224158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.043: 100%|███████████████████████████████████████████████████████████████████████████| 93/93 [00:07<00:00, 12.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch :  65 | loss :  0.04355938203873173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.038: 100%|███████████████████████████████████████████████████████████████████████████| 93/93 [00:07<00:00, 12.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch :  66 | loss :  0.041900006673669304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.038: 100%|███████████████████████████████████████████████████████████████████████████| 93/93 [00:07<00:00, 12.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch :  67 | loss :  0.040946158029699836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.038: 100%|███████████████████████████████████████████████████████████████████████████| 93/93 [00:07<00:00, 12.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch :  68 | loss :  0.039451542720999766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.042: 100%|███████████████████████████████████████████████████████████████████████████| 93/93 [00:07<00:00, 12.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch :  69 | loss :  0.03855082040191979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.035: 100%|███████████████████████████████████████████████████████████████████████████| 93/93 [00:07<00:00, 12.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch :  70 | loss :  0.03776110628599762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "epoch = 70\n",
    "save_dir = './chatbot_data/pretraining/4_chitchat_trasnformer_model/'\n",
    "save_prefix = 'chitchat_transformer'\n",
    "prev_loss_all = float('inf')\n",
    "train_steps = 0\n",
    "test_stpes = 0\n",
    "model.train()\n",
    "\n",
    "for i in range(epoch):\n",
    "    batchloss = 0.0\n",
    "    progress = tqdm(train_dataloader)\n",
    "    for(inputs, y, _) in progress:\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        dec_inputs = y[:, :-1]\n",
    "        outputs = y[:,1:]\n",
    "        \n",
    "        src_mask = model.generate_square_subsequent_mask(MAX_LENGTH).cuda()\n",
    "        src_padding_mask = gen_attension_mask(inputs).cuda()\n",
    "        tgt_mask = model.generate_square_subsequent_mask(MAX_LENGTH-1).cuda()\n",
    "        tgt_padding_mask = gen_attension_mask(dec_inputs).cuda()\n",
    "        \n",
    "        result = model(inputs.long().cuda(), dec_inputs.long().cuda(), src_mask, tgt_mask, src_padding_mask, tgt_padding_mask)\n",
    "        loss = criterion(result.permute(1,2,0), outputs.long().cuda())\n",
    "        progress.set_description(\"{:0.3f}\".format(loss))\n",
    "        \n",
    "        train_steps += 1\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        batchloss += loss\n",
    "        \n",
    "    print(\"train epoch : \",i+1, \"|\",\"loss : \",batchloss.cpu().item() / len(train_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f69181f4-92cc-4b75-b82f-528c4cc5caae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0354, device='cuda:0', grad_fn=<NllLoss2DBackward0>)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "21b48aec-fdba-4f11-8482-adb9232fcd74",
   "metadata": {},
   "outputs": [],
   "source": [
    "save(model, save_dir, save_prefix + \"_\" + str(round(loss.cpu().item(), 6)), i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "68189367-9676-4932-b6c8-b389348d142a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_sentence(sentence):\n",
    "    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
    "    sentence = sentence.strip()\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a480f21e-a39b-427d-8c11-d8bd728ad347",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(sentence):\n",
    "    sentence = preprocess_sentence(sentence)\n",
    "    input = torch.tensor([[2] + vocab.encode_as_ids(sentence) + [3]]).cuda()\n",
    "    output = torch.tensor([[2]]).cuda()\n",
    "\n",
    "    # 디코더의 예측 시작\n",
    "    model.eval()\n",
    "    for i in range(MAX_LENGTH):\n",
    "        src_mask = model.generate_square_subsequent_mask(input.shape[1]).cuda()\n",
    "        tgt_mask = model.generate_square_subsequent_mask(output.shape[1]).cuda()\n",
    "\n",
    "        src_padding_mask = gen_attention_mask(input).cuda()\n",
    "        tgt_padding_mask = gen_attention_mask(output).cuda()\n",
    "\n",
    "        predictions = model(input, output, src_mask, tgt_mask, src_padding_mask, tgt_padding_mask).transpose(0,1)\n",
    "        # 현재(마지막) 시점의 예측 단어를 받아온다.\n",
    "        predictions = predictions[:, -1:, :]\n",
    "        predicted_id = torch.LongTensor(torch.argmax(predictions.cpu(), axis=-1))\n",
    "\n",
    "\n",
    "        # 만약 마지막 시점의 예측 단어가 종료 토큰이라면 예측을 중단\n",
    "        if torch.equal(predicted_id[0][0], torch.tensor(3)):\n",
    "            break\n",
    "\n",
    "        # 마지막 시점의 예측 단어를 출력에 연결한다.\n",
    "        # 이는 for문을 통해서 디코더의 입력으로 사용될 예정이다.\n",
    "        output = torch.cat([output, predicted_id.cuda()], axis=1)\n",
    "\n",
    "    return torch.squeeze(output, axis=0).cpu().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1911d50e-1e6b-42f9-b5bb-5c6ddb698884",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(sentence):\n",
    "    prediction = evaluate(sentence)\n",
    "    predicted_sentence = vocab.Decode(list(map(int,[i for i in prediction if i < vocab_size+7])))\n",
    "\n",
    "    print('Input: {}'.format(sentence))\n",
    "    print('Output: {}'.format(predicted_sentence))\n",
    "\n",
    "    return predicted_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d0e04364-4535-46b0-8772-2879b1d54c4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tformer(\n",
       "  (transformer): Transformer(\n",
       "    (encoder): TransformerEncoder(\n",
       "      (layers): ModuleList(\n",
       "        (0): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=256, out_features=512, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=512, out_features=256, bias=True)\n",
       "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (1): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=256, out_features=512, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=512, out_features=256, bias=True)\n",
       "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (decoder): TransformerDecoder(\n",
       "      (layers): ModuleList(\n",
       "        (0): TransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (multihead_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=256, out_features=512, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=512, out_features=256, bias=True)\n",
       "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          (dropout3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (1): TransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (multihead_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=256, out_features=512, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=512, out_features=256, bias=True)\n",
       "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          (dropout3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (pos_encoder): PositionalEncoding(\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): Embedding(16007, 256)\n",
       "  (pos_encoder_d): PositionalEncoding(\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder_d): Embedding(16007, 256)\n",
       "  (linear): Linear(in_features=256, out_features=16007, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('./chatbot_data/pretraining/4_chitchat_trasnformer_model/chitchat_transformer_0.035401_steps_69.pt'))\n",
    "\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "250505e8-2d32-4724-bebc-6b0eab026aee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 난 뭘 해야 할까?\n",
      "Output: 신경쓰지 말고 직접 힘들 수도 원하는 해봐요.\n"
     ]
    }
   ],
   "source": [
    "result = predict('난 뭘 해야 할까?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8ecb83f5-1256-4bc9-9f93-2b446106d6b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 힘들다\n",
      "Output: 세상에 쉬운 일은 아니었나봐요.\n"
     ]
    }
   ],
   "source": [
    "result = predict('힘들다')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0ad0734d-12eb-4512-9962-aa82887ee06c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 난 혼자인게 싫어\n",
      "Output: 사랑해주는 사람이 있을 거예요.\n"
     ]
    }
   ],
   "source": [
    "result = predict('난 혼자인게 싫어')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "83284634-ff0f-4ec3-9f4c-825a48ed1547",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 뭐가 좋을까?\n",
      "Output: 아무래도 확실한 의사는게 좋겠어요.\n"
     ]
    }
   ],
   "source": [
    "result = predict('뭐가 좋을까?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "de330f0c-1cd5-4cbe-aad4-287511e19bb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 재밌다\n",
      "Output: 저도 저도 즐거워요\n"
     ]
    }
   ],
   "source": [
    "result = predict('재밌다')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e7c8c638-af9a-42fe-a5de-dcc44b350953",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 뭐야\n",
      "Output: 기분이 좀 풀렸길하지 말고 자신이 시작할 수 있다면 연락해보세요.\n"
     ]
    }
   ],
   "source": [
    "result = predict('뭐야')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6663ea75-1125-4fe7-b70a-8f1f8bcdb31f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
